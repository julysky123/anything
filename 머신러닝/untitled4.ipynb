{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e9e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f2174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2cdde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 20\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='./pytorch_실습/data',train = True, download = True, transform = transform)\n",
    "train_data, valid_data = random_split(train_data,[50000,10000])\n",
    "test_data = datasets.MNIST(root='./pytorch_실습/data',train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c19be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bb2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        hidden1 = 512\n",
    "        hidden2 = 512\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        outputs = self.fc3(x)\n",
    "        return outputs\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5794a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.05, momentum=0.9)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87319449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.130591\tValidation Loss: 0.159845\n",
      "Validation loss decreased ([inf -->0.159845]). saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.096796\tValidation Loss: 0.104747\n",
      "Validation loss decreased ([0.159845 -->0.104747]). saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.078208\tValidation Loss: 0.127935\n",
      "Epoch: 4 \tTraining Loss: 0.074148\tValidation Loss: 0.107574\n",
      "Epoch: 5 \tTraining Loss: 0.059599\tValidation Loss: 0.128159\n",
      "Epoch: 6 \tTraining Loss: 0.057636\tValidation Loss: 0.211638\n",
      "Epoch: 7 \tTraining Loss: 0.058265\tValidation Loss: 0.115218\n",
      "Epoch: 8 \tTraining Loss: 0.050603\tValidation Loss: 0.133786\n",
      "Epoch: 9 \tTraining Loss: 0.054982\tValidation Loss: 0.112834\n",
      "Epoch: 10 \tTraining Loss: 0.045656\tValidation Loss: 0.150777\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    model.train()\n",
    "    for x,y in train_loader :\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    for x,y in valid_loader :\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs,y)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(valid_loader)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}\\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1,train_loss,valid_loss\n",
    "    ))\n",
    "    \n",
    "    if valid_loss <= valid_loss_min :\n",
    "        print('Validation loss decreased ([{:.6f} -->{:.6f}]). saving model ...'. format(\n",
    "        valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066dc931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94218e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = [0 for i in range(10)]\n",
    "class_total = [0. for i in range(10)]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x, y in test_loader :\n",
    "    output = model(x)\n",
    "    loss = criterion(output,y)\n",
    "    test_loss += loss.item()\n",
    "    _, preds = torch.max(output,1)\n",
    "    \n",
    "    correct = np.squeeze(preds.eq(y.data.view_as(preds)))\n",
    "    \n",
    "    #정답에는 1이 들어있고 오답에는 0이 들어있다.\n",
    "    for i in range(len(y)):\n",
    "        #label : 정답 index\n",
    "        label = y.data[i]\n",
    "        class_correct[label] +=correct[i].item()\n",
    "        #correct[i].item() 은 0 (오답) 또는 1 (정답)\n",
    "        class_total[label] += 1\n",
    "    \n",
    "test_loss = test_loss/len(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
